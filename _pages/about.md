---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm a first-year Ph.D. student at [University of California, Santa Cruz](https://www.ucsc.edu/), where I am fortunate to be advised by [Prof. Cihang Xie](https://cihangxie.github.io). I received my B.S. degree in Computer Science from [Zhejiang University](https://www.zju.edu.cn/english/) in 2023. Previously, I spent wonderful time at National University of Singapore, Shanghai AI Lab and PhiGent Robotics.

My research interest includes Vision &amp; Language, Multimodal Reprensentation Learning and Data-centric AI. 

<span style="color: red;">I am open for collaborations in research. Also, I am looking for potential research intern positions in the summer of 2025.</span>
<!-- I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# üî• News
- *2024.09*: &nbsp;üöÄ I join VLAA Lab at UCSC as a Ph.D. student!
- *2023.11*: &nbsp; New preprint of MLLMs-Augmented Visual-Language Representation Learning, along with code and datasets!
- *2023.10*: &nbsp; New preprint of the extended version of DREAM (DREAM+), accelerating dataset distillation by 15x!
- *2023.10*: &nbsp; I arrived in Paris for the ICCV 2023 conference. 
- *2023.08*: &nbsp;üöÄ I join HPC-AI Lab at NUS as a research assistant. 
- *2023.07*: &nbsp;üéâ DREAM was accepted by ICCV 2023! 
- *2023.05*: &nbsp;üöÄ I join Shanghai AI Lab as a research intern. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/DREAM_ICCV_2023.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DREAM: Efficient Dataset Distillation by Representative Matching](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.pdf)

**Yanqing Liu**, Jianyang Gu, Kai Wang, Zheng Zhu, Wei Jiang, Yang You

[**Github**](https://github.com/Yanqing0327/DREAM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This work accelerates dataset distillation by over **8x**, significantly improving efficiency.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/pipeline_new.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DREAM+: Efficient Dataset Distillation by Bidirectional Representative Matching](https://arxiv.org/pdf/2310.15052)

**Yanqing Liu**, Jianyang Gu, Kai Wang, Zheng Zhu, Kaipeng Zhang, Wei Jiang, Yang You

[**Github**](https://github.com/Yanqing0327/DREAM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This work presents the extended version of DREAM, achieving a remarkable **15x acceleration** in dataset distillation.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/mllms.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MLLMs-augmented Visual-language Representation Learning](https://arxiv.org/pdf/2311.18765)

**Yanqing Liu**, Kai Wang, Wenqi Shao, Ping Luo, Yu Qiao, Mike Zheng Shou, Kaipeng Zhang, Yang You

[**Github**](https://github.com/Yanqing0327/MLLMs-Augmented) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This work demonstrates the potential of Multimodal Large Language Models (MLLMs) to significantly enhance vision-language pre-training.
</div>
</div>

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2024.09 - now*,     Ph.D. student, University of California, Santa Cruz. 
- *2019.09 - 2023.06*, Undergraduate, College of Computer Science and Technology, Zhejiang Univeristy, Hangzhou.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Internships
- *2023.08 - 2024.06*, [National University of Singapore](https://nus.edu.sg/), Singapore.
- *2023.05 - 2024.06*, [Shanghai AI Lab](https://www.shlab.org.cn/), China.
- *2023.01 - 2023.04*, [PhiGent Robotics](https://www.phigent.ai/en/), China.

# üìÇ Activities
- Reviewer of CVPR 2024, Neurips 2024, AAAI 2025, AISTATS 2025